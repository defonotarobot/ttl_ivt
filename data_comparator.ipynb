{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8f463f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import xlsxwriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26fd1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Config File\n",
    "with open(\"config_comparator.json\") as json_config_file:\n",
    "    config = json.load(json_config_file)\n",
    "\n",
    "# Initialize Variables\n",
    "config_source = config[\"source\"]\n",
    "config_target = config[\"target\"]\n",
    "default_unique_column = config[\"default_unique_column\"]\n",
    "config_faulty = config[\"faulty_dir\"]\n",
    "config_clean = config[\"clean_dir\"]\n",
    "config_output = config[\"output\"]\n",
    "exception_tables = config[\"exception_tables\"]\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b907684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(merged_table, column_number, table_key):\n",
    "\n",
    "    dfc = merged_table.drop(table_key, axis=1)\n",
    "    result = merged_table[[table_key]]\n",
    "    col = 2  # start from third col\n",
    "\n",
    "    isMatched = True\n",
    "    unMatchedColumns = {}\n",
    "\n",
    "    for i in range(0, column_number-1):\n",
    "        # first colon selects all rows, second arg selects col-2 to col\n",
    "        com_col = dfc.iloc[:, col-2:col]\n",
    "\n",
    "        com_col_ret = com_col.iloc[:, 0] == com_col.iloc[:, 1]\n",
    "        com_col_name = 'COM_' + com_col.columns[0][:-2]\n",
    "        com_col[com_col_name] = com_col_ret\n",
    "\n",
    "        unMatchedRet = com_col_ret.loc[com_col_ret[:] == False]\n",
    "        cellUnmatched = len(unMatchedRet) >= 1\n",
    "        isMatched = isMatched and not cellUnmatched\n",
    "\n",
    "        if cellUnmatched:\n",
    "            unMatchedCount = len(unMatchedRet)\n",
    "            unMatchedColumns[com_col.columns[0][:-2]] = unMatchedCount\n",
    "\n",
    "        # comparison logic\n",
    "        # com_col column name defined on the left inside outer bracket\n",
    "        # [0] is the label and [:-2] says to get string from left until\n",
    "        # position -2 as counting from right increases negatively\n",
    "        # com_col values on the first column then set to bool comp logic of\n",
    "        col += 2\n",
    "        result = pd.concat([result, com_col], axis=1)\n",
    "\n",
    "    return {\"data\": result, \"isMatched\": isMatched, \"unMatchedColumns\": unMatchedColumns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd21ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix(tbl, env1, env2):\n",
    "    result = tbl.copy()\n",
    "    for col in result.columns:\n",
    "        new_col = ''\n",
    "        if '_x' in col:\n",
    "            new_col = env1 + '_' + col.removesuffix('_x')\n",
    "        elif '_y' in col:\n",
    "            new_col = env2 + '_' + col.removesuffix('_y')\n",
    "        else:\n",
    "            new_col = col\n",
    "        result = result.rename(columns={col: new_col})\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cd865ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union(tbl, env1, env2, table_key):\n",
    "\n",
    "    y = tbl.copy()\n",
    "    y.insert(1, 'is in ' + env2, y[table_key].isin(df2[table_key]))\n",
    "    y.insert(1, 'is in ' + env1, y[table_key].isin(df1[table_key]))\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keys(column_list, table_keys, delimiter=\",\"):\n",
    "\n",
    "    isComposite = False\n",
    "    matchedResult = False\n",
    "\n",
    "    keys = list(map(str.strip, table_keys.split(delimiter)))\n",
    "    keyCount = len(keys)\n",
    "\n",
    "    if keyCount > 1:\n",
    "        isComposite = True\n",
    "        newKey = \"_\".join(keys)\n",
    "        matchedResult = set(keys).issubset(column_list)\n",
    "    else:\n",
    "        newKey = table_keys\n",
    "        matchedResult = newKey in list(df1.columns)\n",
    "\n",
    "    return {\"isComposite\": isComposite, \"matchedResult\": matchedResult, \"newKey\": newKey, \"keys\": keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_composite_pk(tbl, table_keys, compositeKey, delimiter = \"_\"):\n",
    "\n",
    "    result = tbl.copy()\n",
    "    composite_key_col = pd.DataFrame()\n",
    "    i = 0\n",
    "\n",
    "    for table_key in table_keys:\n",
    "        key_col = tbl.loc[:][table_key]\n",
    "\n",
    "        if i==0:\n",
    "            composite_key_col[compositeKey] = key_col\n",
    "        else:\n",
    "            composite_key_col[compositeKey] = composite_key_col[compositeKey].astype(str) + \"_\" + key_col\n",
    "        \n",
    "        i +=1\n",
    "    \n",
    "    result = pd.concat([result, composite_key_col], axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f490d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "directory = os.fsencode(config_source[\"dir\"])\n",
    "path1 = config_source[\"dir\"]\n",
    "path2 = config_target[\"dir\"]\n",
    "env1 = config_source[\"env\"]\n",
    "env2 = config_target[\"env\"]\n",
    "\n",
    "total_tables = 0\n",
    "total_files = 0\n",
    "\n",
    "for table in os.listdir(directory):\n",
    "    try:\n",
    "        file_name = os.fsdecode(table)\n",
    "        table_name, ext = os.path.splitext(file_name)\n",
    "        file = '\\\\' + file_name\n",
    "\n",
    "        print(\"Table: \" + table_name)\n",
    "\n",
    "        df1 = pd.read_csv(path1 + file, dtype=str).fillna('')\n",
    "        print(\"Loaded data: \" + path1 + file)\n",
    "\n",
    "        df2 = pd.read_csv(path2 + file, dtype=str).fillna('')\n",
    "        print(\"Loaded data: \" + path2 + file)\n",
    "\n",
    "        table_key = default_unique_column\n",
    "\n",
    "        if table_name in exception_tables:\n",
    "            table_key = exception_tables[table_name]\n",
    "\n",
    "        id_present = table_key in list(df1.columns)\n",
    "\n",
    "        check_result = check_keys(df1.columns, table_key)\n",
    "        pri_key = check_result[\"newKey\"]\n",
    "\n",
    "        if check_result[\"matchedResult\"] == True:\n",
    "\n",
    "            # concatenate new pri_key in the table for composite pk table\n",
    "            if check_result[\"isComposite\"] == True:\n",
    "                df1 = insert_composite_pk(df1, check_result[\"keys\"], pri_key)\n",
    "                df2 = insert_composite_pk(df2, check_result[\"keys\"], pri_key)\n",
    "\n",
    "            dfx = df1.merge(df2, on=pri_key,\n",
    "                            how='outer')  # outer join on id\n",
    "            tmp = dfx.reindex(sorted(dfx.columns), axis=1).fillna(\n",
    "                '')  # sorting to make same field adjacent\n",
    "            compare_result = compare(tmp, df1.shape[1], pri_key)  # compare\n",
    "\n",
    "            data = compare_result[\"data\"]\n",
    "            isMatched = compare_result[\"isMatched\"]\n",
    "            print(\"Matching result for table {0} is {1}.\".format(\n",
    "                table_name, isMatched))\n",
    "\n",
    "            if not isMatched:\n",
    "                print(\"Unmatched Columns: {0}\".format(\n",
    "                    compare_result[\"unMatchedColumns\"]))\n",
    "\n",
    "            almost_done = union(data, env1, env2, pri_key)\n",
    "            done = prefix(almost_done, env1, env2)\n",
    "\n",
    "            output_path = config_output[\"dir\"]\n",
    "\n",
    "            if isMatched:\n",
    "                output_path += config_output[\"matched\"]\n",
    "            else:\n",
    "                output_path += config_output[\"unmatched\"]\n",
    "\n",
    "            with pd.ExcelWriter(output_path + env1 + '_' + env2 + '_' + table_name + '.xlsx') as writer:\n",
    "                df1.to_excel(writer, sheet_name=env1, index=False)\n",
    "                df2.to_excel(writer, sheet_name=env2, index=False)\n",
    "                done.to_excel(writer, sheet_name='COM', index=False)\n",
    "            total_files += 1\n",
    "            print(\"Write file for table {0} is completed.\".format(table_name))\n",
    "        else:\n",
    "            print(\"Can't find key for table {0}.\".format(table_name))\n",
    "    except Exception as error:\n",
    "        print(\"Error occurred for table {0}. - {1}\".format(table_name, error))\n",
    "\n",
    "    total_tables += 1\n",
    "    print(\".\")\n",
    "\n",
    "print(\"Total Tables: {0}\".format(total_tables))\n",
    "print(\"Total Output Files: {0}\".format(total_files))\n",
    "\n",
    "print(\">>>>>End Program<<<<<\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824a0a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
